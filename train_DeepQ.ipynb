{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d30cc1b02e48fab61e2b4130b2e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from models.ann import DeepQNet\n",
    "from gridworld.agent import Agent\n",
    "from gridworld.world import World\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: ', device)\n",
    "\n",
    "num_episodes_per_epoch: int = 10\n",
    "num_epochs: int = 1000\n",
    "num_batches_per_epoch: int = 100\n",
    "\n",
    "batch_size: int = 64\n",
    "episode_duration: int = 1000\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "state_action_shape = len(agent.actions) + agent.visual_field.shape[0]\n",
    "policy = DeepQNet(state_action_shape, 1).to(device)\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self) -> None:\n",
    "        self.observations = torch.zeros((0, state_action_shape)).to(device)\n",
    "        self.rewards = torch.zeros(0).to(device)\n",
    "        \n",
    "    def add_experience(self, observation: torch.Tensor, reward: torch.Tensor) -> None:\n",
    "        self.observations = torch.cat((self.observations, observation.to(device)))\n",
    "        self.rewards = torch.cat((self.rewards, reward.to(device)))\n",
    "        \n",
    "    def make_batch(self, batch_size: int):\n",
    "        indices = np.random.randint(0, len(self.observations), batch_size)\n",
    "        memory = ReplayMemory()\n",
    "        memory.add_experience(self.observations[indices], self.rewards[indices])\n",
    "        return memory\n",
    "        \n",
    "memories = ReplayMemory()\n",
    "\n",
    "def simulate_episode(agent: Agent) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    world = World()\n",
    "    observations = torch.zeros((episode_duration, state_action_shape))\n",
    "    rewards = torch.zeros(episode_duration)\n",
    "    \n",
    "    t = 0\n",
    "    for t in range(episode_duration):\n",
    "        action: int = np.random.randint(0, len(agent.actions))\n",
    "        action_vector = torch.zeros(len(agent.actions))\n",
    "        action_vector[action] = 1.0\n",
    "        \n",
    "        observations[t,:agent.visual_field.shape[0]] = agent.update_visual_field(world)\n",
    "        observations[t,agent.visual_field.shape[0]:] = action_vector\n",
    "        rewards[t] = agent.step(action, world)\n",
    "        \n",
    "    return observations[:t], rewards[:t], t\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(policy.parameters(), lr=0.01)\n",
    "loss_history = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    total_loss = 0.0\n",
    "    for _ in range(num_episodes_per_epoch):\n",
    "        observations, rewards, duration = simulate_episode(agent)\n",
    "        memories.add_experience(observations, rewards)\n",
    "\n",
    "    for _ in range(num_batches_per_epoch):\n",
    "        batch = memories.make_batch(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        predicted_rewards = policy(batch.observations)\n",
    "        loss = loss_fn(predicted_rewards, batch.rewards.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    loss_history.append(total_loss / num_batches_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"policy_{timestamp}.pth\"\n",
    "torch.save(policy.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mplot(loss_history)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [MSE]')\n",
    "print('Final loss:', loss_history[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
